{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pips and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OTYQWOcNFfWd",
        "outputId": "f164bfd9-94fd-43ac-aa19-51549d64c43a"
      },
      "outputs": [],
      "source": [
        "# Pip Installs, run this cell only once per computer\n",
        "!pip install tqdm\n",
        "!pip install transformers timm\n",
        "!pip install --upgrade kagglehub\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eaW94mXJVPFh",
        "outputId": "39843af7-1ca7-4f81-e6d2-4208db70ad18"
      },
      "outputs": [],
      "source": [
        "#imports run this cell every time you open this code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "from tiny_vit import tiny_vit_21m_224\n",
        "import os\n",
        "import math\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from collections import Counter\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLK0jWoBgzM3",
        "outputId": "596ff66c-c714-47cb-f23c-3b49a9f8db17"
      },
      "outputs": [],
      "source": [
        "# Download the dataset from KaggleHub. If you already have it downloaded from when you ran this program earlier, it won't redownload. It will simply save the current directory (in other words run this every time)\n",
        "path = kagglehub.dataset_download(\"ubitquitin/geolocation-geoguessr-images-50k\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5sj6CN1DvYH"
      },
      "outputs": [],
      "source": [
        "# These are the important file paths\n",
        "DATA_PATH = path + '/compressed_dataset' #Path for your dataset. By default it is set to the kagglehub dataset path, but if you want to train on your own dataset you can import it here.\n",
        "MODEL_PATH = '/content/tiny_vit_model_geoguessr_(0.0048 - 92.88%).pth' #where you want to save and load your own weights\n",
        "PRETRAINED_PATH = \"/content/tiny_vit_model_geoguessr_(0.0048 - 92.88%).pth\" #These are the weights for the pretrained model. Run off this if its your first time training the AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJqUVSjoWcgD",
        "outputId": "d5999485-105a-4514-e019-4a7949f1439a"
      },
      "outputs": [],
      "source": [
        "# === Device setup ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #The 'device' variable defines wether we want to run this on CUDA (more powerful) or CPU (more common)\n",
        "\n",
        "# === Transform === (Resizes input images to correct format)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  #Aspect ratio for tiny_vit\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# === Dataset ===\n",
        "dataset = ImageFolder(DATA_PATH, transform=transform) #ImageFolder is a dataset class made by pytorch. It takes image folders and makes bundles them into tensors that work with the model and parallel processing\n",
        "class_names = dataset.classes #the names of every country\n",
        "num_classes = len(class_names) #since the AI can't output words, we have it output numbers instead. Each number corresponds to a country.\n",
        "\n",
        "# === Train/test split === (This section splits our dataset into two subsets: training and testing. Since we don't want to test the model's accuracy on pictures it has seen before, we put aside 20% of the dataset to be used for testing)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "test_size = total_size - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) #this creates the training and testing datasets\n",
        "\n",
        "# === Compute class weights for training data only === (This is to normalize the fact that some countries have more images than others. This mean the program can get stuck in a local minimum by simply selecting something like 'United States', because the dataset might be 20% United States. This makes it so that every country is weighed the same, and offsets for repeatedly appearing countries)\n",
        "train_indices = train_dataset.indices  # indices from original dataset\n",
        "train_targets = [dataset.targets[i] for i in train_indices]\n",
        "class_counts = Counter(train_targets)\n",
        "\n",
        "class_weights = [0.0] * num_classes\n",
        "for i in range(num_classes):\n",
        "      class_weights[i] = total_size / (num_classes * class_counts[i]) if class_counts[i] > 0 else 0.0\n",
        "\n",
        "sample_weights = [class_weights[label] for label in train_targets]\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# === DataLoaders === (This turns our datasets into dataloaders. It makes it so that datasets are loaded in batches (for parallel processing), and images are chosen in random order.)\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler) #for training\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE) #for testing\n",
        "\n",
        "# === Model === (This is where we define our model.)\n",
        "class GeoGuessrAI(nn.Module):\n",
        "    def __init__(self, num_classes=124):\n",
        "        super(GeoGuessrAI, self).__init__()\n",
        "        self.base_model = tiny_vit_21m_224(pretrained=True)\n",
        "        self.base_model.head = nn.Linear(self.base_model.head.in_features, num_classes) #we need to make sure the model is trained on num_classes (number of countries we are testing for, in this case 124). A model trained on a 124 country dataset will not work on a 125 country dataset\n",
        "\n",
        "    def forward(self, x): #The forward function returns an output for a given image\n",
        "        return self.base_model(x)\n",
        "\n",
        "model = GeoGuessrAI(num_classes=num_classes).to(device) #We assign the model to a variable and set the number of classes to \n",
        "\n",
        "# === Load Pretrained Weights === (This loads weights from the pretrained model. We can load our own weights later)\n",
        "state_dict = torch.load(PRETRAINED_PATH)\n",
        "\n",
        "\n",
        "# === Loss & Optimizer === (These are very important functions to our neural network. We took many iterations to find the best values for these)\n",
        "criterion = nn.CrossEntropyLoss() # This is the loss function. It is responsible for back propogation, and eveluates the model on how sure it was on its guess. The model will output \"I'm 20% sure this is Tanzania\" and evaluate it on that\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.05) #This is an imported optimizer function. It finds the best optimizations for the model, as well as the learning rate\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True) #it is always best to have the optimizers learning rate be dynaMIC. This scheduler tweaks the learning rate based on what is necessary at any given time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "05vzpYa58ikL",
        "outputId": "6cb4b533-d448-44ab-f90f-1bb55136c098"
      },
      "outputs": [],
      "source": [
        "#Run this cell to load your own weights (do this if you have already started training the model and want to pick up from where you left off\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "n4kcal6aU8v8",
        "outputId": "4b067320-1c18-40a8-88b0-a9c500f7767d"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000 #How many times we want to iterate over the dataset\n",
        "best_loss = float('inf') #variable to keep track of which weights work best\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train() #puts the model in training mode\n",
        "    running_loss = 0.0 #tracks loss over a whole epoch\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\") #this is just code for the loading bar at the bottom\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device) #This makes sure our tensors are being processed in the right device (GPU/CPU)\n",
        "\n",
        "        # === Standard Training Loop Core ===\n",
        "        optimizer.zero_grad() #This is necessary to running the optimizer\n",
        "        outputs = model(images) #runs the model and sees what its current outputs are\n",
        "        loss = criterion(outputs, labels) # Calculates loss over the batch\n",
        "        loss.backward() #does backward propogation\n",
        "        optimizer.step() #necessary for the optimizer\n",
        "\n",
        "        running_loss += loss.item() #add this batch's loss the the epoch's loss\n",
        "        loop.set_postfix(loss=loss.item()) #only visual\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"\\nEpoch {epoch+1} complete. Average loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # === Save these wights only if they are better than the previous one ===\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        print(f\"New best model saved with loss {best_loss:.4f}\")\n",
        "    else:\n",
        "        print(f\"Loss did not improve. Keeping previous model with loss {best_loss:.4f}\")\n",
        "\n",
        "\n",
        "    scheduler.step(avg_loss)#Tweak the learning rate of the optimizer with the scheduler\n",
        "\n",
        "    # === Test Accuracy ===\n",
        "    model.eval() # Puts the model in evaluation mode\n",
        "    correct = total = 0 #variables to compare correct guesses with total guesses\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device) #import dataset to device\n",
        "            outputs = model(images) #run the model on an image\n",
        "            _, predicted = torch.max(outputs.data, 1) #turns the output tensor into tangible answers/guesses\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total#calculate accuracy\n",
        "    print(f\"Test Accuracy after Epoch {epoch+1}: {accuracy:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnBNFviwEg1I",
        "outputId": "8bf9673e-7d3d-4e90-8602-58bde3036d8e"
      },
      "outputs": [],
      "source": [
        "input_photo_path = 'Enter the image filepath you want'\n",
        "\n",
        "dataset = ImageFolder(DATA_PATH, transform=transform)\n",
        "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()} #This turns our output values back into to country names\n",
        "\n",
        "# === Prediction Function ===\n",
        "def test_image(image_path, model, transform, device, idx_to_class):\n",
        "    image = Image.open(image_path) #opens the image in python\n",
        "\n",
        "    if image.mode == 'RGBA':\n",
        "        image = image.convert('RGB') #converts to proper format\n",
        "\n",
        "    image = transform(image).unsqueeze(0).to(device) #formats to proper resolution\n",
        "    model.eval() #puts the model in evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, predicted_class = torch.max(outputs, 1)#compares output to predicted value\n",
        "\n",
        "    return idx_to_class[predicted_class.item()]\n",
        "\n",
        "# Prediction\n",
        "predicted_country = test_image(input_photo_path, model, transform, device, idx_to_class)\n",
        "print(f\"Predicted country: {predicted_country}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
